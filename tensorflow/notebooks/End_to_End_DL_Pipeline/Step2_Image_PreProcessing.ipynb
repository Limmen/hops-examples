{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for PreProcessing Images Using TFRecords and the Dataset API in Tensorflow. Notebook (2/6) in the End-to-End Scalable Deep Learning Pipeline on Hops.\n",
    "\n",
    "This notebook will read the TFRecords that were written by notebook number 1 ([Notebook number one](./Step1_Convert_To_TFRecords.ipynb)) and run them through a preprocessing pipeline that includes:\n",
    "\n",
    "- Random shuffling of train/val/test datasets\n",
    "- Data augmentation of the train dataset, including:\n",
    "\n",
    "- Random flipping of an image (Left-to-Right, not upside-down)\n",
    "- Random adjustment of the brightness in the image\n",
    "- Random saturation of the RGB channels in the image\n",
    "\n",
    "The notebook also includes simple data exploration/validation to inspect the processed images and verify them.\n",
    "\n",
    "This notebook read TFRecords from:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw\n",
    "\n",
    "And output TFRecords to:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean\n",
    "\n",
    "Running this computation separate from the training can make the training more performance, especially if your CPUs for preprocessing is the bottleneck. \n",
    "\n",
    "![step2.png](./../images/step2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Tested with versions:\n",
    "\n",
    "- numpy: 1.14.5\n",
    "- hops: 2.6.4\n",
    "- pydoop: 2.0a3\n",
    "- tensorboard: 1.8.0\n",
    "- tensorflow: 1.8.0\n",
    "- tensorflow-gpu: 1.8.0\n",
    "- tfspark: 1.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>824</td><td>application_1536227070932_0146</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hadoop30:8088/proxy/application_1536227070932_0146/\">Link</a></td><td><a target=\"_blank\" href=\"http://hadoop23:8042/node/containerlogs/container_e59_1536227070932_0146_01_000001/ImageNet_EndToEnd_MLPipeline__kimham00\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "/srv/hops/anaconda/anaconda/envs/ImageNet_EndToEnd_MLPipeline/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pydoop.hdfs as py_hdfs\n",
    "from hops import hdfs\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = hdfs.project_path()\n",
    "DATASET_BASE_DIR = PROJECT_DIR + \"tiny-imagenet/tiny-imagenet-200/\"\n",
    "TFR_DIR = DATASET_BASE_DIR + \"tfrecords_raw/\"\n",
    "OUTPUT_DIR = DATASET_BASE_DIR + \"tfrecords_clean/\"\n",
    "TRAIN_TFR_DIR = TFR_DIR + \"train/\"\n",
    "VAL_TFR_DIR = TFR_DIR + \"val/\"\n",
    "TRAIN_DIR = DATASET_BASE_DIR + \"train\"\n",
    "TEST_TFR_DIR = TFR_DIR + \"test/\"\n",
    "TF_FILE_PATTERN = \"*.tfrecords\"\n",
    "ID_TO_CLASS_FILE = DATASET_BASE_DIR + \"/words.txt\"\n",
    "VAL_LABELS_FILE = DATASET_BASE_DIR + \"val/val_annotations.txt\"\n",
    "# This file is written by the other notebook when converting JPEGs to TFRecords, \n",
    "# it includes the number of files in train/val/test, which is required to shuffle the dataset correctly \n",
    "SIZES_FILE = DATASET_BASE_DIR + \"sizes.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Metadata about the Dataset\n",
    "\n",
    "The dataset has some .txt files with annotation and other metadata that needs to be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata():\n",
    "    \"\"\" \n",
    "    Parses the words.txt file into a map of label -> words and a list of ordered nids (index of nid = integer label).\n",
    "    Also parses the val_annotations.txt file into a map of (validation_file_name --> nid)\n",
    "    \"\"\"\n",
    "    # list all directories in the train set, the directory name is the \"nid\" and identifies the label\n",
    "    train_dirs = py_hdfs.ls(TRAIN_DIR)\n",
    "    \n",
    "    # remove the path except the nid\n",
    "    train_nid_list = list(map(lambda x: x.replace(TRAIN_DIR + \"/\", \"\"), train_dirs))\n",
    "    \n",
    "    # the number of nids equal then number of unique classes/labels\n",
    "    num_classes = len(train_nid_list)\n",
    "    \n",
    "    # read the words.txt file that contains lines of the form \"nid\\twords\"\n",
    "    with py_hdfs.open(ID_TO_CLASS_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    label_to_word = {}\n",
    "    \n",
    "    for l in file_lines:\n",
    "        # parse each line\n",
    "        wnid, word = l.split('\\t')\n",
    "        if wnid in train_nid_list:\n",
    "            # convert the nids into integer labels by using the position in the index\n",
    "            label = train_nid_list.index(wnid)\n",
    "            word = str(label) + \": \" + word\n",
    "            # save the mapping of integer label --> words\n",
    "            label_to_word[label] = word\n",
    "    \n",
    "    # read the val_annotations.txt file that contains lines of the form: \n",
    "    # \"validation_image\\tnid\\tx_pos\\ty_pos\\tw_pos\\th_pos\"\n",
    "    with py_hdfs.open(VAL_LABELS_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    validation_file_to_nid = {}\n",
    "    for l in file_lines:\n",
    "        # parse each line\n",
    "        tokens = l.split('\\t')\n",
    "        #skip corrupted lines\n",
    "        if len(tokens) > 2:\n",
    "            validation_img = tokens[0]\n",
    "            wnid = tokens[1]\n",
    "            # we only care about classification in this tutorial, not localization \n",
    "            if wnid in train_nid_list:\n",
    "                validation_file_to_nid[validation_img] = wnid\n",
    "    \n",
    "    return train_nid_list, label_to_word, validation_file_to_nid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect FileNames and Dataset Size from HopsFS\n",
    "\n",
    "In the first notebook, we recorded the number of records in each dataset (train/val/test) and wrote these statistics to a file in HopsFS. Here we will read and parse that file. We need to know the number of records in each dataset to be able to do correct shuffling of the data, and since the Dataset API is \"lazy\" we cannot just apply dataset.size() to get the number of records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames_and_size():\n",
    "    \"\"\"\n",
    "    A function for obtaining all the resting TFRecord files to be parsed.\n",
    "    We need to merge the TFRecords to be able to shuffle and batch the dataset.\n",
    "    \"\"\"\n",
    "    # Convert regular expression file pattern into a list of files (tfrecords files)\n",
    "    train_tfr_files = tf.gfile.Glob(TRAIN_TFR_DIR + TF_FILE_PATTERN)\n",
    "    val_tfr_files = tf.gfile.Glob(VAL_TFR_DIR + TF_FILE_PATTERN)\n",
    "    test_tfr_files = tf.gfile.Glob(TEST_TFR_DIR + TF_FILE_PATTERN)\n",
    "    \n",
    "    # Read sizes.txt that to get the size of the datasets (used for correct shuffling)\n",
    "    with py_hdfs.open(SIZES_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")    \n",
    "    train_size = int(file_lines[0].split(\",\")[1])\n",
    "    val_size = int(file_lines[1].split(\",\")[1])\n",
    "    test_size = int(file_lines[2].split(\",\")[1])\n",
    "    \n",
    "    return train_tfr_files, val_tfr_files, test_tfr_files, train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading TFRecords into Tensorflow Datasets\n",
    "tf.data is the newest API for building data pipelines into deep learning models and it is what we will use.\n",
    "\n",
    "A tf.data.Dataset represents a sequence of elements, in which each element contains one or more Tensor objects. In our case we are reading the TFRecords stored in HopsFS into one dataset for train, one for val and one for test. The elements in the datasets will be one tensor for the image and one tensor for the one-hot encoded label. \n",
    "\n",
    "The datasets are \"lazy\" and data will only be read from the resting TFRecords when required for computation or explicitly called through an iterator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(files):\n",
    "    \"\"\"\n",
    "     A function for creating a TF dataset from TFR files\n",
    "    \"\"\"\n",
    "    # Parse train dataset from a list of TFRecords files\n",
    "    dataset = tf.data.TFRecordDataset(files,\n",
    "        compression_type=None,    \n",
    "        buffer_size=100240, \n",
    "        num_parallel_reads=os.cpu_count() # Parallel read from HopsFS\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_tfr_files, val_tfr_files, test_tfr_files):\n",
    "    \"\"\"\n",
    "     A function for creating TensorFlow datasets for \n",
    "     train,val, and test from TFR files\n",
    "    \"\"\"\n",
    "    # Parse train dataset from a list of TFRecords files\n",
    "    train_dataset = create_dataset(train_tfr_files)\n",
    "\n",
    "    # Parse validation dataset from a list of TFRecords files\n",
    "    val_dataset = create_dataset(val_tfr_files)\n",
    "\n",
    "    # Parse test dataset from a list of TFRecords files\n",
    "    test_dataset = create_dataset(test_tfr_files)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Parsing and Preprocessing\n",
    "\n",
    "Since images are serialized into a binary TFRecords format, they need to be parsed into in-memory tensors to perform image preprocessing.\n",
    "\n",
    "Image preprocessing can include: resizing, augmenting, normalizing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr(example_proto):\n",
    "    \"\"\"\n",
    "    Parses an example protocol buffer (TFRecord) into a dict of\n",
    "    feature names and tensors\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'height': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'width': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'channel': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'label': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'label_one_hot': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'image_raw': tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
    "    }\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    return parsed_features[\"image_raw\"], parsed_features[\"label_one_hot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bytes(image, label):\n",
    "    \"\"\"\n",
    "    Decode the bytes that was serialized in the TFRecords in HopsFS to tensors so that we can apply \n",
    "    image preprocessing\n",
    "    \"\"\"\n",
    "    image_tensor = tf.decode_raw(image, tf.uint8),\n",
    "    label_tensor = tf.decode_raw(label, tf.uint8),\n",
    "    image_tensor = tf.reshape(image_tensor, [64,64,3]) #dimension information was lost when serializing to disk\n",
    "    return image_tensor,label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, label):\n",
    "    \"\"\"\n",
    "    Function for resizing an image to 64x64 pixels\n",
    "    \"\"\"\n",
    "    resized_image = tf.image.resize_images(image, [64, 64])\n",
    "    return resized_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_data_aug(image, label):\n",
    "    \"\"\"\n",
    "    Function for performing image augmentation \n",
    "    (a technique that can improve classifier performance and reduce overfitting)\n",
    "    \"\"\"\n",
    "    # Randomly flip an image horizontally (left to right).\n",
    "    # With a 1 in 2 chance, outputs the contents of image flipped \n",
    "    # along the second dimension, which is width. \n",
    "    # Otherwise output the image as-is.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    # Adjust the brightness of images by a random factor.\n",
    "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
    "    \n",
    "    # Adjust the saturation of an RGB image by a random factor.\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Image Processing Pipeline\n",
    "\n",
    "With the dataset API different processing stages can easily be chained together into a pipeline, just like it would be done in functional programming or in a framework like Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pre_process_pipeline(dataset, dataset_size, test_or_val_set = False):\n",
    "    \"\"\"\n",
    "    Pipeline for parsing, shuffling, preprocessing, and batching a dataset of images and labels\n",
    "    \"\"\"\n",
    "    # Parse the binary TFR format into dataset\n",
    "    dataset = dataset.map(parse_tfr)\n",
    "    # Decode the bytestrings into tensors\n",
    "    dataset = dataset.map(decode_bytes)\n",
    "    # Randomly shuffle the elements in the dataset\n",
    "    dataset = dataset.shuffle(dataset_size)\n",
    "    # Perform data augmentation on the tensors\n",
    "    if not test_or_val_set:\n",
    "        dataset = dataset.map(image_data_aug, num_parallel_calls=os.cpu_count())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Creating an iterator over the dataset \n",
    "    \"\"\"\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_element_op = iterator.get_next()\n",
    "    return next_element_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tensorflow Library to Save the PreProcessed Images and Labels into TFRecords\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "        'label_one_hot': _bytes_feature(label_one_hot_raw),\n",
    "        'image_raw': _bytes_feature(img_raw)\n",
    "}\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"\n",
    "    Wrapper for inserting bytes features into Example proto.\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfr_example(image, label):\n",
    "    \"\"\" \n",
    "    Creates a TFRecord Example Protobuf binary format\n",
    "    \"\"\"\n",
    "    image_raw = image.tostring()\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature={\n",
    "        'label_one_hot': _bytes_feature(bytes(label[0])),\n",
    "        'image_raw': _bytes_feature(image_raw)\n",
    "    }))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Validation\n",
    "\n",
    "Lets first try to parse some sample TFRecords that were written by notebook number 1 ([Notebook number one](./TinyImageNet_Convert_To_TFRecords.ipynb)) to verify that the parsing works correctly and that the data looks like it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse metadata so we can transform numeric label into description\n",
    "train_nid_list, label_to_word, validation_file_to_nid = parse_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing some sample train images and their labels:\n",
    "```python\n",
    "def one_hot_to_int(label):\n",
    "    return list(label).index(1)\n",
    "\n",
    "dataset = create_dataset(\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/45.tfrecords\")\n",
    "dataset = dataset.map(parse_tfr)\n",
    "dataset = dataset.map(decode_bytes)\n",
    "dataset_iterate_op = iterate_over_dataset(dataset)\n",
    "sample_images = []\n",
    "sample_labels= []\n",
    "with tf.Session() as sess:\n",
    "    for i in range(6):\n",
    "        element = sess.run(dataset_iterate_op)\n",
    "        image = element[0]\n",
    "        label = element[1]\n",
    "        sample_images.append(image)\n",
    "        sample_labels.append(label[0])\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = (14,10)\n",
    "count = 0\n",
    "for i in range(len(sample_images)):\n",
    "    count += 1\n",
    "    plt.subplot(3,3,count)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title('label: {}'.format(label_to_word[one_hot_to_int(sample_labels[i])]))\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(\"sample_images_from_tfr.png\")\n",
    "plt.show()\n",
    "```\n",
    "![sample_images_from_tfr.png](./../images/sample_images_from_tfr.png)\n",
    "\n",
    "Parsing some sample validation images and their labels:\n",
    "```python\n",
    "def one_hot_to_int(label):\n",
    "    return list(label).index(1)\n",
    "\n",
    "dataset = create_dataset(\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/val/val.tfrecords\")\n",
    "dataset = dataset.map(parse_tfr)\n",
    "dataset = dataset.map(decode_bytes)\n",
    "dataset_iterate_op = iterate_over_dataset(dataset)\n",
    "sample_images = []\n",
    "sample_labels= []\n",
    "with tf.Session() as sess:\n",
    "    for i in range(24):\n",
    "        element = sess.run(dataset_iterate_op)\n",
    "        image = element[0]\n",
    "        label = element[1]\n",
    "        sample_images.append(image)\n",
    "        sample_labels.append(label[0])\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = (14,50)\n",
    "count = 0\n",
    "for i in range(len(sample_images)):\n",
    "    count += 1\n",
    "    plt.subplot(3,3,count)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title('label: {}'.format(label_to_word[one_hot_to_int(sample_labels[i])]))\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(\"sample_images_from_tfr_val.png\")\n",
    "plt.show()\n",
    "```\n",
    "![sample_images_from_tfr_val.png](./../images/sample_images_from_tfr_val.png)\n",
    "\n",
    "As we can see, the images look like they should and we were able to parse them correctly form the binary strings stored in the Protobuf messages on HopsFS. Moreover, the labels are now correctly grouped together with each example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "The datasets and the operations on them in Tensorflow are actual nodes in the Tensorflow graph so we need to create a Tensorflow session to run it in order to see some results. For each example that we read and preprocess, we write it out again to a new directory in HopsFS, this means that we can process arbitrarily large datasets since we do not need to store more than a few examples at a time in RAM memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_filename, val_filename, test_filename):\n",
    "    \"\"\"\n",
    "    Orchestrates the pipeline and runs the steps in order:\n",
    "    1. Get files\n",
    "    2. Define datasets\n",
    "    3. Define computational graph over datasets for preprocessing\n",
    "    4. Iterate overdataset by perprocessing and saving the results to TFRecords again\n",
    "    \"\"\"\n",
    "    # Get files\n",
    "    train_tfr_files, val_tfr_files, test_tfr_files, train_size, val_size, test_size = get_filenames_and_size()\n",
    "    # Get datasets (lazy)\n",
    "    train_dataset, val_dataset, test_dataset = create_datasets(train_tfr_files, val_tfr_files, test_tfr_files)\n",
    "    \n",
    "    # train \n",
    "    train_dataset = image_pre_process_pipeline(train_dataset, train_size)\n",
    "    train_dataset_iterate_op = iterate_over_dataset(train_dataset)\n",
    "    \n",
    "    # val\n",
    "    val_dataset = image_pre_process_pipeline(val_dataset, val_size, test_or_val_set = True)\n",
    "    val_dataset_iterate_op = iterate_over_dataset(val_dataset)\n",
    "    \n",
    "    # test\n",
    "    test_dataset = image_pre_process_pipeline(test_dataset, test_size, test_or_val_set = False)\n",
    "    test_dataset_iterate_op = iterate_over_dataset(test_dataset)\n",
    "    \n",
    "    # Run the graph and save output to TFRecords\n",
    "    with tf.Session() as sess:\n",
    "        train_writer = tf.python_io.TFRecordWriter(train_filename)\n",
    "        for i in range(train_size):\n",
    "            element = sess.run(train_dataset_iterate_op)\n",
    "            image = element[0]\n",
    "            label = element[1]\n",
    "            tfr_example = create_tfr_example(image, label)\n",
    "            train_writer.write(tfr_example.SerializeToString())\n",
    "        \n",
    "        val_writer = tf.python_io.TFRecordWriter(val_filename)\n",
    "        for i in range(val_size):\n",
    "            element = sess.run(val_dataset_iterate_op)\n",
    "            image = element[0]\n",
    "            label = element[1]\n",
    "            tfr_example = create_tfr_example(image, label)\n",
    "            val_writer.write(tfr_example.SerializeToString())\n",
    "        \n",
    "        test_writer = tf.python_io.TFRecordWriter(test_filename)\n",
    "        for i in range(test_size):\n",
    "            element = sess.run(test_dataset_iterate_op)\n",
    "            image = element[0]\n",
    "            label = element[1]\n",
    "            tfr_example = create_tfr_example(image, label)\n",
    "            test_writer.write(tfr_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook entrypoint, kicking off the pipeline\n",
    "run(OUTPUT_DIR + \"train.tfrecords\", OUTPUT_DIR + \"val.tfrecords\", OUTPUT_DIR + \"test.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation Step Two\n",
    "If everything went Okay, the data should be written to HopsFS into three different files:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean/train.tfrecords\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean/val.tfrecords\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean/test.tfrecords\n",
    "\n",
    "These files contains preprocessed data that is ready to be fed into a machine learning model for training or evaluation. All three files are shuffled, and only `train.tfrecords` contains data that is preprocessed by random perturbations such as:\n",
    "\n",
    "- Random flipping of an image (Left-to-Right, not upside-down)\n",
    "- Random adjustment of the brightness in the image\n",
    "- Random saturation of the RGB channels in the image\n",
    "\n",
    "Let's have a look at a few sample images from the train dataset to see that everything worked correctly:\n",
    "\n",
    "```python\n",
    "dataset = create_dataset(\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean/train.tfrecords\")\n",
    "dataset = dataset.map(parse_tfr)\n",
    "dataset = dataset.map(decode_bytes)\n",
    "dataset_iterate_op = iterate_over_dataset(dataset)\n",
    "sample_images = []\n",
    "sample_labels= []\n",
    "with tf.Session() as sess:\n",
    "    for i in range(24):\n",
    "        element = sess.run(dataset_iterate_op)\n",
    "        image = element[0]\n",
    "        label = element[1]\n",
    "        sample_images.append(image)\n",
    "        sample_labels.append(label[0])\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = (14,50)\n",
    "count = 0\n",
    "for i in range(len(sample_images)):\n",
    "    count += 1\n",
    "    plt.subplot(12,3,count)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title('label: {}'.format(label_to_word[one_hot_to_int(sample_labels[i])]))\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(\"sample_images_preprocessed_from_tfr.png\")\n",
    "plt.show()\n",
    "```\n",
    "![sample_images_preprocessed_from_tfr.png](./../images/sample_images_preprocessed_from_tfr.png)\n",
    "\n",
    "And some samples from the validation set: \n",
    "\n",
    "```python\n",
    "dataset = create_dataset(\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean/val.tfrecords\")\n",
    "dataset = dataset.map(parse_tfr)\n",
    "dataset = dataset.map(decode_bytes)\n",
    "dataset_iterate_op = iterate_over_dataset(dataset)\n",
    "sample_images = []\n",
    "sample_labels= []\n",
    "with tf.Session() as sess:\n",
    "    for i in range(24):\n",
    "        element = sess.run(dataset_iterate_op)\n",
    "        image = element[0]\n",
    "        label = element[1]\n",
    "        sample_images.append(image)\n",
    "        sample_labels.append(label[0])\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = (14,50)\n",
    "count = 0\n",
    "for i in range(len(sample_images)):\n",
    "    count += 1\n",
    "    plt.subplot(12,3,count)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title('label: {}'.format(label_to_word[one_hot_to_int(sample_labels[i])]))\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(\"sample_images_preprocessed_from_tfr_val.png\")\n",
    "plt.show()\n",
    "```\n",
    "![sample_images_preprocessed_from_tfr_val.png](./../images/sample_images_preprocessed_from_tfr_val.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
