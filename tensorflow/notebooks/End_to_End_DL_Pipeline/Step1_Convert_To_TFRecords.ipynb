{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Conversion from JPEGs to TFRecords with feature and labels. Notebook (1/6) in the End-to-End Scalable Deep Learning Pipeline on Hops.\n",
    "\n",
    "TinyImageNet dataset contains a training set of 100,000 images, a validation set of 10,000 images, and a test\n",
    "set of also 10,000 images. These images are sourced from 200 different classes of objects. The images are downscaled from the original ImageNet’s dataset size of 256x256 to 64x64. \n",
    "\n",
    "The two initial tasks before we can train a model on this dataset are:\n",
    "\n",
    "1. Group the images with their labels \n",
    "2. Convert the JPEGs into TFRecords\n",
    "\n",
    "When using large datasets, like ImageNet, dealing with JPEGs is not very efficient, nor compatible with all of the functionality in the Tensorflow framework. \n",
    "\n",
    "TFRecords is a binary format for representing features and labels in Tensoflow, using a binary format for a large dataset can have a huge impact on disk space and processing speed. In addition, TFRecords are easier to work with than working with the raw JPEGs.\n",
    "\n",
    "![step1.png](./../images/step2.png)\n",
    "\n",
    "This notebook read JPEGs and labels from:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/val\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/test\n",
    "\n",
    "and dataset metadata from:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/words.txt\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/val/val_annotations.txt\n",
    "\n",
    "The notebook output TFRecords to:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw\n",
    "\n",
    "and dataset statistics (number of records in each dataset (train/val/test)) to:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/sizes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports\n",
    "\n",
    "Tested with versions:\n",
    "\n",
    "- numpy: 1.14.5\n",
    "- hops: 2.6.4\n",
    "- pydoop: 2.0a3\n",
    "- tensorboard: 1.8.0\n",
    "- tensorflow: 1.8.0\n",
    "- tensorflow-gpu: 1.8.0\n",
    "- tfspark: 1.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>853</td><td>application_1536227070932_0179</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hadoop30:8088/proxy/application_1536227070932_0179/\">Link</a></td><td><a target=\"_blank\" href=\"http://hadoop13:8042/node/containerlogs/container_e59_1536227070932_0179_01_000001/ImageNet_EndToEnd_MLPipeline__kimham00\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "/srv/hops/anaconda/anaconda/envs/ImageNet_EndToEnd_MLPipeline/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pydoop.hdfs as py_hdfs\n",
    "from hops import hdfs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = hdfs.project_path()\n",
    "DATASET_BASE_DIR = PROJECT_DIR + \"tiny-imagenet/tiny-imagenet-200/\"\n",
    "TRAIN_DIR = DATASET_BASE_DIR + \"train\"\n",
    "TEST_DIR = DATASET_BASE_DIR + \"test\"\n",
    "VAL_DIR = DATASET_BASE_DIR + \"val/images/\"\n",
    "ID_TO_CLASS_FILE = DATASET_BASE_DIR + \"/words.txt\"\n",
    "OUTPUT_DIR = DATASET_BASE_DIR + \"tfrecords_raw/\"\n",
    "VAL_LABELS_FILE = DATASET_BASE_DIR + \"val/val_annotations.txt\"\n",
    "FILE_PATTERN = \"*.JPEG\"\n",
    "SIZES_FILE = DATASET_BASE_DIR + \"sizes.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Metadata about the Dataset\n",
    "\n",
    "The dataset has some .txt files with annotation and other metadata that needs to be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata():\n",
    "    \"\"\" \n",
    "    Parses the words.txt file into a map of label -> words and a list of ordered nids (index of nid = integer label).\n",
    "    Also parses the val_annotations.txt file into a map of (validation_file_name --> nid)\n",
    "    \"\"\"\n",
    "    # list all directories in the train set, the directory name is the \"nid\" and identifies the label\n",
    "    train_dirs = py_hdfs.ls(TRAIN_DIR)\n",
    "    \n",
    "    # remove the path except the nid\n",
    "    train_nid_list = list(map(lambda x: x.replace(TRAIN_DIR + \"/\", \"\"), train_dirs))\n",
    "    \n",
    "    # the number of nids equal then number of unique classes/labels\n",
    "    num_classes = len(train_nid_list)\n",
    "    \n",
    "    # read the words.txt file that contains lines of the form \"nid\\twords\"\n",
    "    with py_hdfs.open(ID_TO_CLASS_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    label_to_word = {}\n",
    "    \n",
    "    for l in file_lines:\n",
    "        # parse each line\n",
    "        wnid, word = l.split('\\t')\n",
    "        if wnid in train_nid_list:\n",
    "            # convert the nids into integer labels by using the position in the index\n",
    "            label = train_nid_list.index(wnid)\n",
    "            word = str(label) + \": \" + word\n",
    "            # save the mapping of integer label --> words\n",
    "            label_to_word[label] = word\n",
    "    \n",
    "    # read the val_annotations.txt file that contains lines of the form: \n",
    "    # \"validation_image\\tnid\\tx_pos\\ty_pos\\tw_pos\\th_pos\"\n",
    "    with py_hdfs.open(VAL_LABELS_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    validation_file_to_nid = {}\n",
    "    for l in file_lines:\n",
    "        # parse each line\n",
    "        tokens = l.split('\\t')\n",
    "        #skip corrupted lines\n",
    "        if len(tokens) > 2:\n",
    "            validation_img = tokens[0]\n",
    "            wnid = tokens[1]\n",
    "            # we only care about classification in this tutorial, not localization \n",
    "            if wnid in train_nid_list:\n",
    "                validation_file_to_nid[validation_img] = wnid\n",
    "    \n",
    "    return train_nid_list, label_to_word, validation_file_to_nid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at a few sample images from the dataset:\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sample_images = [\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01443537/images/n01443537_327.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01443537/images/n01443537_328.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01698640/images/n01698640_381.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01882714/images/n01882714_300.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01770393/images/n01770393_101.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01774750/images/n01774750_24.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n01784675/images/n01784675_101.JPEG\",\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/train/n09332890/images/n09332890_300.JPEG\"]\n",
    "img_op_0 = tf.image.decode_jpeg(tf.read_file(sample_images[0]))\n",
    "img_op_1 = tf.image.decode_jpeg(tf.read_file(sample_images[1]))\n",
    "img_op_2 = tf.image.decode_jpeg(tf.read_file(sample_images[2]))\n",
    "img_op_3 = tf.image.decode_jpeg(tf.read_file(sample_images[3]))\n",
    "img_op_4 = tf.image.decode_jpeg(tf.read_file(sample_images[4]))\n",
    "img_op_5 = tf.image.decode_jpeg(tf.read_file(sample_images[5]))\n",
    "img_op_6 = tf.image.decode_jpeg(tf.read_file(sample_images[6]))\n",
    "img_op_7 = tf.image.decode_jpeg(tf.read_file(sample_images[7]))\n",
    "sample_images_parsed = []\n",
    "with tf.Session() as sess:\n",
    "    sample_images_parsed.append(img_op_0.eval())\n",
    "    sample_images_parsed.append(img_op_1.eval())\n",
    "    sample_images_parsed.append(img_op_2.eval())\n",
    "    sample_images_parsed.append(img_op_3.eval())\n",
    "    sample_images_parsed.append(img_op_4.eval())\n",
    "    sample_images_parsed.append(img_op_5.eval())\n",
    "    sample_images_parsed.append(img_op_6.eval())\n",
    "    sample_images_parsed.append(img_op_7.eval())\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14,10)\n",
    "count = 0\n",
    "for img in sample_images_parsed:\n",
    "    count += 1\n",
    "    plt.subplot(4,4,count)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig(\"sample_images.png\")\n",
    "plt.show()\n",
    "```\n",
    "![sample_images.png](./../images/sample_images.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_examples_per_class = list(map(lambda d: len(py_hdfs.ls(d + \"/images/\")), py_hdfs.ls(TRAIN_DIR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the class distribution in the train set\n",
    "```python\n",
    "plt.hist(sizes, bins='auto')\n",
    "plt.xlabel('Number of examples)')\n",
    "plt.ylabel('Number of classes')\n",
    "plt.title('Class distribution histogram')\n",
    "plt.savefig(\"class_distribution.png\")\n",
    "plt.show()\n",
    "```\n",
    "![class_distribution.png](./../images/class_distribution.png)\n",
    "\n",
    "As we can see, the examples are uniformly distributed over the classes. In the training dataset there are 200 classes with 500 examples in each (total 100 000 images in the training dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Tensorflow Computational Graph for the Computation of Reading and Parsing Files and Labels\n",
    "\n",
    "The graph uses Queues to read concurrently using all available threads on the machine. The graph contains of very few operations, where the main operations are `img_reader.read` and  `tf.image.decode_jpeg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_graph():\n",
    "    \"\"\" \n",
    "    Initialize the graph and variables for Tensorflow engine \n",
    "    \"\"\"\n",
    "    # get operation for initializing the global variables in the graph\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    \n",
    "    # create a session for encapsulating the environment where \n",
    "    # operations can be run and tensors can be evaluated\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # run the initialization operation\n",
    "    sess.run(init_g)\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_for_processing_dir(files_dir, file_pattern, base_dir, nid_list, test_dir=False, val_dir=False):\n",
    "    \"\"\"\n",
    "    Builds the computational graph for parsing images and labels\n",
    "    from a directory in HopsFS.\n",
    "    The images are parsed into tensors and their corresponding label.\n",
    "    \"\"\"\n",
    "    # Convert regular expression file pattern into a list of files (images)\n",
    "    img_filenames = tf.gfile.Glob(files_dir + file_pattern)\n",
    "    \n",
    "    # Create a queue of the filenames (images)\n",
    "    img_queue = tf.train.string_input_producer(img_filenames)\n",
    "    \n",
    "    # Get the number of images to parse\n",
    "    num_images = len(img_filenames)\n",
    "    \n",
    "    # Setup a reader for reading the queue of filenames\n",
    "    # This reader will read the entire contents of a file as a value and returns (filename, filecontents)\n",
    "    img_reader = tf.WholeFileReader()\n",
    "    \n",
    "    # Operation for reading a single file from the queue\n",
    "    file_name_op, file_contents_op = img_reader.read(img_queue)\n",
    "    \n",
    "    if test_dir or val_dir:\n",
    "        # We don't have labels for testset, for simplicity just set it to -1 and save in the same structure as\n",
    "        # val/train records\n",
    "        # Similarly, for validation directory we do not have a single label for a directory so we have to infer\n",
    "        # it per file instead, it will be done dynamically when the graph is run so just set the label to -1 here.\n",
    "        label = -1\n",
    "    else:\n",
    "        # Infer the label using the nid_list and the directory name\n",
    "        label = nid_list.index(files_dir.replace(base_dir, \"\").replace(\"/images\", \"\").replace(\"/\", \"\"))\n",
    "        \n",
    "    # Operation for decoding JPEG to tensor\n",
    "    img_to_tensor_op = tf.image.decode_jpeg(file_contents_op)\n",
    "    \n",
    "    return img_to_tensor_op, label, file_name_op, num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_for_processing_dir(sess, img_op, label, file_name_op, num_images, files_dir, nid_list, validation_file_to_nid, val_dir=False):\n",
    "    \"\"\"\n",
    "    Runs the computational graph for parsing images from HopsFS into tensors and their label\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    # Size of the queue\n",
    "    print(\"Reading {} files from directory {}\".format(num_images, files_dir))\n",
    "    #for i in range(num_images):\n",
    "    for i in range(num_images):\n",
    "        # these two must be run in the same call to sess.run() otherwise they become unsynced which messes up labels for validation set..\n",
    "        img_tensor, file_name_str = sess.run([img_op, file_name_op])\n",
    "        # For validation directory we have to infer labels per file rather than per directory\n",
    "        # We do this using the metadata file val_annotations.txt and the filename\n",
    "        if val_dir:\n",
    "            label = nid_list.index(validation_file_to_nid[file_name_str.decode(\"utf-8\").replace(VAL_DIR, \"\")])\n",
    "        # 2% of the data is not colored... just skipping these for now\n",
    "        # Can convert these to 3 channel grey scale but not sure if it is worth it\n",
    "        if img_tensor.shape == (64,64,3):\n",
    "            images.append(img_tensor)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tensorflow Library to Save the Parsed Files and Labels into TFRecords\n",
    "\n",
    "A TFRecords file contains a sequence of binary strings (multiple records). Since it is just bytes you can write anything to this file but for it to be easily read by Tensorflow later on, we should stick to Tensorflow's pre-defined binary formats.\n",
    "\n",
    "Tensorflow have two predefined protocol buffer message types that you can use: Example and SequenceExample. SequenceExample is designed for data where you can have variable number of features, whereas Example is better if you always are storing the exact same data structure for each record.\n",
    "\n",
    "An Example protocol buffer message is simply a map of string keys to values, where the values are list of integers, floats or bytes.\n",
    "\n",
    "In our case, we are working with multi-class classification or images and we will use an Example of the format:\n",
    "\n",
    "```json\n",
    "{\n",
    "        'height': _int64_feature(height),\n",
    "        'width': _int64_feature(width),\n",
    "        'channel': _int64_feature(channels),\n",
    "        'label': _int64_feature(label),\n",
    "        'label_one_hot': _bytes_feature(label_one_hot_raw),\n",
    "        'image_raw': _bytes_feature(img_raw)\n",
    "}\n",
    "```\n",
    "Each value in the map is an instance of a Tensorflow tf.train.Feature, which can be int, float, or byte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    \"\"\"\n",
    "    Wrapper for inserting int64 features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"\n",
    "    Wrapper for inserting bytes features into Example proto.\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onehot_encoder(num_labels):\n",
    "    \"\"\" \n",
    "    Creates a matrix where\n",
    "    matrix[i] gives the one_hot_encoded version of integer label i\n",
    "    \"\"\"\n",
    "    onehot_lookup = []\n",
    "    for i in range(0, num_labels):\n",
    "        temp = [0] * num_labels\n",
    "        temp[i] = 1\n",
    "        onehot_lookup.append(temp)\n",
    "    return onehot_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_records(images, labels, filename, onehot_lookup):\n",
    "    \"\"\" \n",
    "    Saves a list of images and a list of corresponding labels into TFRecords on HopsFS\n",
    "    \"\"\"\n",
    "    print(\"Converting the parsed images to TFRecords and saving to file: {}\".format(filename))\n",
    "    num_examples = labels.shape[0]\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError(\"Images size %d does not match label size %d.\" % (images.shape[0], num_examples))\n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "    depth = images.shape[3]\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'channel': _int64_feature(depth),\n",
    "            'label': _int64_feature(int(labels[index])),\n",
    "            'label_one_hot': _bytes_feature(bytes(onehot_lookup[int(labels[index])])),\n",
    "            'image_raw': _bytes_feature(image_raw)\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it All Together Into a Wrapper Function\n",
    "\n",
    "The function is designed to process one directory at a time, so that we can paralellize the execution using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir(files_dir, file_pattern, base_dir, output_category):\n",
    "    \"\"\"\n",
    "    This function orchestrates the conversion from JPEGs to TFRecords of a single directory\n",
    "    It initiates and builds the computational graph,\n",
    "    runs the conversion and saves resulting TFRecords to HopsFS\n",
    "    \"\"\"\n",
    "    # Parse dataset metadata and annotation files\n",
    "    # Get list of orderd nids, a map of label-->words from the words.txt file,\n",
    "    # and a map of validation_img --> nid from the val_annotations.txt file\n",
    "    nid_list, label_to_word, validation_file_to_nid = parse_metadata()\n",
    "    # Create a matrix for converting integers into one-hot-encoding\n",
    "    onehot_lookup = _onehot_encoder(len(nid_list))\n",
    "    # If we are processing a test directory there are no labels\n",
    "    test_dir = output_category == \"test/\"\n",
    "    # If we are processing a validation directory the labels are not in the directory names but from\n",
    "    # the val_annotations.txt file\n",
    "    val_dir = output_category == \"val/\"\n",
    "    # Build graph and get necessary tensorflow operations\n",
    "    img_dir_op, dir_label, file_name_op, img_dir_filenames = build_graph_for_processing_dir(files_dir, file_pattern, base_dir, nid_list, test_dir=test_dir, val_dir=val_dir)\n",
    "\n",
    "    # Initialize TF\n",
    "    sess = init_graph()\n",
    "\n",
    "    # Get coordinator for threads to be able to read\n",
    "    coord = tf.train.Coordinator()\n",
    "\n",
    "    # Starts all queue runners in the graph and return list of the threads\n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "    # Run the graph for each image to read it and convert to a tensor\n",
    "    images, labels = run_graph_for_processing_dir(sess, img_dir_op, dir_label, file_name_op, img_dir_filenames, files_dir, nid_list, validation_file_to_nid, val_dir=val_dir)\n",
    "    \n",
    "    # Convert the images and labels to tf records saved on disk\n",
    "    if test_dir:\n",
    "        filename = OUTPUT_DIR + output_category + \"test\" + \".tfrecords\"\n",
    "    if val_dir:\n",
    "        filename = OUTPUT_DIR + output_category + \"val\" + \".tfrecords\"\n",
    "    if not test_dir and not val_dir:\n",
    "        filename = OUTPUT_DIR + output_category + str(labels[0]) + \".tfrecords\"\n",
    "    \n",
    "    num_written_records = len(images)\n",
    "    \n",
    "    convert_to_tf_records(images, labels, filename, onehot_lookup)\n",
    "    \n",
    "    print(\"num_written_records: {}\".format(num_written_records))\n",
    "    \n",
    "    # Cleanup this session\n",
    "    sess.close()\n",
    "    \n",
    "    return (filename, output_category, num_written_records) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel/Distributed Processing of the Dataset\n",
    "\n",
    "Processing the files and converting the data into TFRecords is an embarrasingly parallel operation, we can utilize spark for doing this in a scalable manner. \n",
    "\n",
    "Simple benchmark shows that preprocessing the TinyImageNet dataset using 1 machine takes around 20 minutes, but with 8 machines it completed in 4.5 minutes. \n",
    "\n",
    "Using the same technique for processing the entire ImageNet will be crucial for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files were written to HopsFS (202): hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/0.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/1.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/2.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/3.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/4.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/5.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/6.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/7.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/8.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/9.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/10.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/11.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/12.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/13.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/14.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/15.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/16.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/17.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/18.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/19.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/20.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/21.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/22.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/23.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/24.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/25.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/26.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/27.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/28.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/29.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/30.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/31.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/32.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/33.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/34.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/35.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/36.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/37.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/38.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/39.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/40.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/41.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/42.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/43.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/44.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/45.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/46.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/47.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/48.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/49.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/50.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/51.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/52.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/53.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/54.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/55.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/56.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/57.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/58.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/59.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/60.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/61.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/62.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/63.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/64.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/65.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/66.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/67.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/68.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/69.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/70.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/71.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/72.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/73.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/74.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/75.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/76.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/77.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/78.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/79.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/80.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/81.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/82.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/83.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/84.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/85.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/86.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/87.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/88.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/89.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/90.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/91.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/92.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/93.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/94.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/95.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/96.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/97.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/98.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/99.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/100.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/101.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/102.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/103.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/104.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/105.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/106.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/107.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/108.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/109.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/110.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/111.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/112.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/113.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/114.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/115.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/116.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/117.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/118.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/119.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/120.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/121.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/122.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/123.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/124.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/125.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/126.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/127.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/128.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/129.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/130.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/131.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/132.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/133.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/134.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/135.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/136.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/137.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/138.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/139.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/140.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/141.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/142.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/143.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/144.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/145.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/146.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/147.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/148.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/149.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/150.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/151.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/152.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/153.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/154.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/155.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/156.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/157.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/158.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/159.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/160.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/161.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/162.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/163.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/164.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/165.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/166.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/167.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/168.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/169.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/170.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/171.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/172.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/173.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/174.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/175.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/176.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/177.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/178.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/179.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/180.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/181.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/182.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/183.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/184.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/185.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/186.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/187.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/188.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/189.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/190.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/191.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/192.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/193.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/194.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/195.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/196.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/197.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/198.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/train/199.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/val/val.tfrecords,hdfs://10.0.104.196:8020/Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_raw/test/test.tfrecords\n",
      "Number of train records total: 98179\n",
      "Number of val records total: 9832\n",
      "Number of test records total: 9811"
     ]
    }
   ],
   "source": [
    "# Get all training directories from HopsFS and save into tuple (output_sub_dir, directory path)\n",
    "train_dirs = list(map(lambda x: (\"train/\", x + \"/images/\"), py_hdfs.ls(TRAIN_DIR)))\n",
    "\n",
    "# Get the single validation directory from HopsFS and save into tuple (output_sub_dir, directory path)\n",
    "validation_dir = [(\"val/\", VAL_DIR)]\n",
    "\n",
    "# Get the single test directory from HopsFS and save into tuple (output_sub_dir, directory path)\n",
    "test_dir = [(\"test/\", TEST_DIR + \"/images/\")]\n",
    "\n",
    "# Concat all directories that should be processed and convert into an RDD\n",
    "dir_rdd = spark.sparkContext.parallelize(train_dirs + validation_dir + test_dir)\n",
    "\n",
    "# Process the directories in paralell using spark, writing out TFRecords to HopsFS\n",
    "result = dir_rdd.map(lambda dir_tuple: process_dir(dir_tuple[1], FILE_PATTERN, TRAIN_DIR, dir_tuple[0])).collect()\n",
    "\n",
    "# Collect results and write some statistics to HopsFS and to the log\n",
    "files_written = list(map(lambda x: x[0], result))\n",
    "train_records_count = sum(list(map(lambda x: int(x[2]), filter(lambda y: y[1] == \"train/\", result))))\n",
    "val_records_count = sum(list(map(lambda x: int(x[2]), filter(lambda y: y[1] == \"val/\", result))))\n",
    "test_records_count = sum(list(map(lambda x: int(x[2]), filter(lambda y: y[1] == \"test/\", result))))\n",
    "print(\"The following files were written to HopsFS ({}): {}\".format(len(files_written), \",\".join(files_written)))\n",
    "print(\"Number of train records total: {}\".format(train_records_count))\n",
    "print(\"Number of val records total: {}\".format(val_records_count))\n",
    "print(\"Number of test records total: {}\".format(test_records_count))\n",
    "py_hdfs.dump(\"train,{}\\nval,{}\\ntest,{}\".format(train_records_count,val_records_count,test_records_count), SIZES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
