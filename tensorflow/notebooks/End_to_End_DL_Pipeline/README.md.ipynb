{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# End-to-End Distributed Deep Learning Pipeline on Hops\n",
    "\n",
    "<h1 style=\"color:red\">This pipeline have been tested with the python dependencies:</h1>\n",
    "\n",
    "- numpy: 1.14.5\n",
    "- hops: 2.6.4\n",
    "- pydoop: 2.0a3\n",
    "- tensorboard: 1.8.0\n",
    "- tensorflow: 1.8.0\n",
    "- tensorflow-gpu: 1.8.0\n",
    "- tfspark: 1.3.5\n",
    "\n",
    "<h1 style=\"color:red\">The notebooks assumes that you have downloaded the TinyImageNet dataset</h1>\n",
    "\n",
    "- You can download the dataset from [here](https://tiny-imagenet.herokuapp.com/)\n",
    "- Unzip the dataset in your project root so that you have the following directory layout:\n",
    "\n",
    "```\n",
    "\n",
    "Projects\n",
    "        |\n",
    "        --YourProjectName\n",
    "                        |\n",
    "                        --tiny-imagenet\n",
    "                                      |\n",
    "                                      --tiny-imagenet-200\n",
    "                                                         |\n",
    "                                                         --test\n",
    "                                                         --train\n",
    "                                                         --val\n",
    "                                                         --wnids.txt\n",
    "                                                         etc.\n",
    "                                         \n",
    "           \n",
    "```\n",
    " - The same pipeline can also be used for training on the larger ImageNet dataset, you just need to change the dimensions in from 64x64x3 images to 224x224x3 and make sure that you have a similar directory layout\n",
    "\n",
    "===\n",
    "\n",
    "## Step 1: Parse the Raw Dataset, join Features with Labels, Save to TFRecords\n",
    "\n",
    "[Step1_Notebook](./Step1_Convert_To_TFRecords.ipynb)\n",
    "\n",
    "![step1.png](./../images/step1.png)\n",
    "\n",
    "## Step 2: PreProcess Images (Data augmentation, normalization, shuffling etc)\n",
    "\n",
    "[Step2_Notebook](./Step2_Image_PreProcessing.ipynb)\n",
    "\n",
    "![step2.png](./../images/step2.png)\n",
    "\n",
    "\n",
    "## Step 3: Single Machine Training Using Distributed Hyperparameter Search and Model Iteration using Reproducible Experiments\n",
    "\n",
    "[Step3_Notebook](./Step3_Model_Training_Parallel_Experiments.ipynb)\n",
    "\n",
    "![step3.png](./../images/step3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multiple GPU Training Using the Ring-All-Reduce Architecture\n",
    "\n",
    "[Step4.0_Notebook](./Step4.0_Horovod_Launch.ipynb)\n",
    "\n",
    "[Step4_Notebook](./Step4_Ring_AllReduce_GPU_Training.ipynb)\n",
    "\n",
    "![step4.png](./../images/step4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Serving\n",
    "\n",
    "[Step5_Notebook](./Step5_Model_Serving.ipynb)\n",
    "\n",
    "![step5.png](./../images/step5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
