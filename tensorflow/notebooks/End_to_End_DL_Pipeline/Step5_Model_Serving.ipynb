{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Serving The Trained Model for Classifying TinyImageNet. Notebook (6/6) in the End-to-End Scalable Deep Learning Pipeline on Hops.\n",
    "\n",
    "\n",
    "This notebook will read the exported model that was written to HopsFS by notebook number 4 ([Notebook number two](./Step4_Ring_AllReduce_GPU_Training.ipynb)) and set it up for serving and also perform some sample queries against it.\n",
    "\n",
    "Specifically, this notebook reads the model from:\n",
    "\n",
    "- hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/exported_model\n",
    "\n",
    "![step5.png](./../images/step5.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TensorFlow Serving Through The HopsWorks UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![serving1.png](./../images/serving_1.png)\n",
    "![serving2.png](./../images/serving_2.png)\n",
    "![serving3.png](./../images/serving_3.png)\n",
    "![serving4.png](./../images/serving_4.png)\n",
    "![serving5.png](./../images/serving_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model By Writing a gRPC Client \n",
    "\n",
    "We can use the validation set and compare predictions against the labels to see where the model gets it wrong and where it gets it right.\n",
    "\n",
    "You can inspect the exported model using tensorflow command line tool to know what inputs the model expects and what output it will give.\n",
    "\n",
    "```bash\n",
    "saved_model_cli show --dir /home/kim/workspace/imagenet_serving/1 --all\n",
    "```\n",
    "\n",
    "In future, Tensorflow will support REST clients and servers for models, but right now the framwork relies on gRPC for communication between client and server.\n",
    "\n",
    "In gRPC a client application can directly call methods on a server application on a different machine as if it was a local object, making it easier for you to create distributed applications and services. As in many RPC systems, gRPC is based around the idea of defining a service, specifying the methods that can be called remotely with their parameters and return types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from grpc.beta import implementations\n",
    "from tensorflow.contrib.util import make_tensor_proto\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def create_dataset(files):\n",
    "    \"\"\"\n",
    "     A function for creating a TF dataset from TFR files\n",
    "    \"\"\"\n",
    "    # Parse train dataset from a list of TFRecords files\n",
    "    dataset = tf.data.TFRecordDataset(files,\n",
    "        compression_type=None,    \n",
    "        buffer_size=100240, \n",
    "        num_parallel_reads=os.cpu_count() # Parallel read from HopsFS\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def parse_tfr(example_proto):\n",
    "    \"\"\"\n",
    "    Parses an example protocol buffer (TFRecord) into a dict of\n",
    "    feature names and tensors\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'height': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'width': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'channel': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'label': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'label_one_hot': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'image_raw': tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
    "    }\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    return parsed_features[\"image_raw\"], parsed_features[\"label_one_hot\"]\n",
    "\n",
    "def decode_bytes(image, label):\n",
    "    \"\"\"\n",
    "    Decode the bytes that was serialized in the TFRecords in HopsFS to tensors so that we can apply \n",
    "    image preprocessing\n",
    "    \"\"\"\n",
    "    image_tensor = tf.decode_raw(image, tf.uint8),\n",
    "    label_tensor = tf.decode_raw(label, tf.uint8),\n",
    "    image_tensor = tf.reshape(image_tensor, [64,64,3]) #dimension information was lost when serializing to disk\n",
    "    return image_tensor,label_tensor\n",
    "\n",
    "def iterate_over_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Creating an iterator over the dataset \n",
    "    \"\"\"\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_element_op = iterator.get_next()\n",
    "    return next_element_op\n",
    "\n",
    "def get_one_batch():\n",
    "    dataset = create_dataset(\"hdfs:///Projects/ImageNet_EndToEnd_MLPipeline/tiny-imagenet/tiny-imagenet-200/tfrecords_clean/val.tfrecords\")\n",
    "    dataset = dataset.map(parse_tfr)\n",
    "    dataset = dataset.map(decode_bytes)\n",
    "    dataset_iterate_op = iterate_over_dataset(dataset)\n",
    "    sample_images = []\n",
    "    sample_labels= []\n",
    "    with tf.Session() as sess:\n",
    "        for i in range(100):\n",
    "            element = sess.run(dataset_iterate_op)\n",
    "            image = element[0]\n",
    "            label = element[1]\n",
    "            sample_images.append(image)\n",
    "            sample_labels.append(label[0])\n",
    "    return sample_images, sample_labels\n",
    "\n",
    "def make_stub():\n",
    "    channel = implementations.insecure_channel(\"0.0.0.0\", 7777) # update this to match your port and IP \n",
    "    stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "    return stub\n",
    "\n",
    "\n",
    "def make_request(sample_images):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"tinyimagenet\"\n",
    "    request.model_spec.signature_name = \"serving_default\"\n",
    "    request.inputs['input'].CopyFrom(make_tensor_proto(np.array(sample_images), shape=[100, 64, 64, 3]))\n",
    "    return request\n",
    "\n",
    "def parse_metadata():\n",
    "    \"\"\" \n",
    "    Parses the words.txt file into a map of label -> words and a list of ordered nids (index of nid = integer label).\n",
    "    Also parses the val_annotations.txt file into a map of (validation_file_name --> nid)\n",
    "    \"\"\"\n",
    "    # list all directories in the train set, the directory name is the \"nid\" and identifies the label\n",
    "    train_dirs = py_hdfs.ls(TRAIN_DIR)\n",
    "    \n",
    "    # remove the path except the nid\n",
    "    train_nid_list = list(map(lambda x: x.replace(TRAIN_DIR + \"/\", \"\"), train_dirs))\n",
    "    \n",
    "    # the number of nids equal then number of unique classes/labels\n",
    "    num_classes = len(train_nid_list)\n",
    "    \n",
    "    # read the words.txt file that contains lines of the form \"nid\\twords\"\n",
    "    with py_hdfs.open(ID_TO_CLASS_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    label_to_word = {}\n",
    "    \n",
    "    for l in file_lines:\n",
    "        # parse each line\n",
    "        wnid, word = l.split('\\t')\n",
    "        if wnid in train_nid_list:\n",
    "            # convert the nids into integer labels by using the position in the index\n",
    "            label = train_nid_list.index(wnid)\n",
    "            word = str(label) + \": \" + word\n",
    "            # save the mapping of integer label --> words\n",
    "            label_to_word[label] = word\n",
    "    \n",
    "    # read the val_annotations.txt file that contains lines of the form: \n",
    "    # \"validation_image\\tnid\\tx_pos\\ty_pos\\tw_pos\\th_pos\"\n",
    "    with py_hdfs.open(VAL_LABELS_FILE, 'r') as f:\n",
    "        file_lines = f.read().decode(\"utf-8\").split(\"\\n\")\n",
    "    validation_file_to_nid = {}\n",
    "    for l in file_lines:\n",
    "        # parse each line\n",
    "        tokens = l.split('\\t')\n",
    "        #skip corrupted lines\n",
    "        if len(tokens) > 2:\n",
    "            validation_img = tokens[0]\n",
    "            wnid = tokens[1]\n",
    "            # we only care about classification in this tutorial, not localization \n",
    "            if wnid in train_nid_list:\n",
    "                validation_file_to_nid[validation_img] = wnid\n",
    "    \n",
    "    return train_nid_list, label_to_word, validation_file_to_nid\n",
    "\n",
    "batch_images, batch_labels = get_one_batch()\n",
    "stub = make_stub()\n",
    "request = make_request(batch_images)\n",
    "result = stub.Predict(request, 1000.0) #1000 secs timeout (100 examples through resnet is pretty slow on CPU)\n",
    "train_nid_list, label_to_word, validation_file_to_nid = parse_metadata() \n",
    "plt.rcParams[\"figure.figsize\"] = (14,50)\n",
    "count = 0\n",
    "for i in range(24):\n",
    "    count += 1\n",
    "    plt.subplot(12,2,count)\n",
    "    plt.imshow(batch_images[i])\n",
    "    plt.title('label: {}\\n prediction: {}'.format(label_to_word[list(batch_labels[i]).index(1)],label_to_word[result.outputs['class_ids'].int_val[i]]))\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./prediction_images.png\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![prediction_images.png](./../images/prediction_images.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
